{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Exploration and Visualization of Cosmic Strings in CMB\n",
    "This notebook explores the Cosmic Microwave Background (CMB) data to identify potential cosmic string candidates."
   ],
   "id": "623af29cb778d5b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initial exploration of the CMB data using Healpy and Matplotlib.",
   "id": "398cb6ea7138181e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install required packages\n",
    "# pip freeze > requirements.txt\n",
    "!pip install -r requirements.txt"
   ],
   "id": "69c5c13035d2a730",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First exploring the COM_CMB_IQU-smica_2048_R3.00_full.fits file to understand its structure and contents.",
   "id": "8505d0be0a0656f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.constants.codata2014 import alpha\n",
    "from scipy.constants import h, c, k\n",
    "import healpy as hp\n",
    "\n",
    "# Planck function (spectral radiance)\n",
    "def planck(f, T):\n",
    "    x = h * f / (k * T)\n",
    "    return (2 * h * f**3 / c**2) / np.expm1(x)\n",
    "\n",
    "\n",
    "# Frequency range (Hz)\n",
    "frequencies = np.linspace(1e10, 1e12, 1000)  # 10 GHz to 1000 GHz\n",
    "temperature = 2.725  # CMB temperature in Kelvin\n",
    "\n",
    "# Compute spectral radiance\n",
    "radiance = planck(frequencies, temperature)\n",
    "\n",
    "# Plot spectrum\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies / 1e9, radiance, color='darkblue', label=f'T = {temperature} K')\n",
    "plt.title('CMB Blackbody Spectrum at T = 2.725 K')\n",
    "plt.xlabel('Frequency (GHz)')\n",
    "plt.ylabel('Spectral Radiance B(ν) [W·sr⁻¹·m⁻²·Hz⁻¹]')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4c33cfad7c5af566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "# Load a Planck CMB temperature map\n",
    "cmb_map = hp.read_map('data/COM_CMB_IQU-smica_2048_R3.00_full.fits', field=0)\n",
    "\n",
    "# Not ideal for CMB structure detection\n",
    "# cmb_map = hp.read_map('data/HFI_SkyMap_100_2048_R3.01_full.fits', field=0)\n",
    "\n",
    "\n",
    "# Convert to 2D image\n",
    "nside = hp.get_nside(cmb_map)\n",
    "npix = hp.nside2npix(nside)\n",
    "# Convert the CMB map to a 2D image for visualization\n",
    "img = hp.mollview(cmb_map, return_projected_map=True, nest=False, title='CMB Temperature Map', cmap='inferno', xsize=2000, hold=True)\n"
   ],
   "id": "f4d3f330ff83f3fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply edge detection (e.g., Sobel)edges = ndimage.sobel(img)\n",
    "# Plot the edges detected in the CMB map\n",
    "edges = ndimage.sobel(img)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path('./edge')\n",
    "\n",
    "if not folder_path.exists():\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Folder '{folder_path}' created successfully!\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' already exists.\")\n",
    "\n",
    "# Save to .fits\n",
    "from astropy.io import fits\n",
    "# Save as 2D FITS image\n",
    "hdu = fits.PrimaryHDU(edges.astype(np.float32))\n",
    "hdu.writeto(\"edge/edge_detected_image.fits\", overwrite=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.imshow(edges, cmap='inferno')\n",
    "plt.title('Possible Cosmic String Candidates (Edges in CMB)')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ],
   "id": "2dfa72a8288c9645",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Load or define your image (already done)\n",
    "# img = ...\n",
    "\n",
    "# --- Step 2: Force-clean the CMB image ---\n",
    "# Replace NaNs, -inf, +inf with zeros (or median)\n",
    "img_cleaned = np.nan_to_num(img, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# --- Step 3: Edge detection ---\n",
    "edges = ndimage.sobel(img_cleaned)\n",
    "\n",
    "# --- Step 4: Print CLEANED ranges ---\n",
    "print(\"Cleaned CMB image range:\", np.min(img_cleaned), \"to\", np.max(img_cleaned))\n",
    "print(\"Edge image range:\", np.min(edges), \"to\", np.max(edges))\n",
    "\n",
    "# --- Step 5: Normalize for plotting ---\n",
    "def normalize(arr):\n",
    "    arr = np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return (arr - np.min(arr)) / (np.ptp(arr) + 1e-8)\n",
    "\n",
    "img_norm = normalize(img_cleaned)\n",
    "edges_norm = normalize(edges)\n",
    "\n",
    "# Optional: Threshold edges for clarity\n",
    "edges_thresh = np.where(edges_norm > 0.3, 1.0, 0.0)\n",
    "\n",
    "# --- Step 6: Plot overlay ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.imshow(img_norm, cmap='coolwarm',alpha=0.9, origin='lower', aspect='auto')\n",
    "plt.imshow(edges_thresh, cmap='YlOrBr', alpha=0.9, origin='lower', aspect='auto')\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.title(\"CMB with Edge Overlay (cleaned)\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cmb_edge_overlay_cleaned.png\", dpi=300)\n",
    "plt.show()\n"
   ],
   "id": "4b455d9a45c7e271",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Nonlinear exaggeration\n",
    "edges_exaggerated = edges**0.9  # or try 2.0\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.imshow(edges_exaggerated, cmap='turbo')\n",
    "plt.title('Possible Cosmic String Candidates (Edges in CMB)')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "id": "2b9e6d04a881e700",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sharp_edges = edges + 0.7 * edges  # amplify edge intensity\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.imshow(sharp_edges, cmap='inferno')\n",
    "plt.title('Possible Cosmic String Candidates (Edges in CMB)')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ],
   "id": "9fea3233b6b0440d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Alter this code block\n",
    "# Apply edge detection (e.g., Sobel)edges = ndimage.sobel(img)\n",
    "# Plot the edges detected in the CMB map\n",
    "# Apply Sobel in x and y directions\n",
    "dx = ndimage.sobel(img, axis=0) ** 0.5\n",
    "dy = ndimage.sobel(img, axis=1) ** 0.5\n",
    "\n",
    "# Gradient magnitude\n",
    "edges = np.hypot(dx, dy)  # Same as sqrt(dx**2 + dy**2)\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "plt.imshow(edges, cmap='inferno')\n",
    "plt.title('Possible Cosmic String Candidates (Edges in CMB)')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ],
   "id": "ef325655c7cb6d9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frequencies = np.linspace(10e9, 1000e9, 1000)  # 10 GHz to 1000 GHz\n",
    "\n",
    "T_mean = 2.725\n",
    "delta_T = 100e-6  # 100 µK typical fluctuation\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean), label=\"T = 2.725 K\", color='blue')\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean + delta_T), '--', label=\"+100 µK\", color='green', alpha=0.8)\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean - delta_T), '--', label=\"-100 µK\", color='red', alpha=0.8)\n",
    "plt.xlabel(\"Frequency (GHz)\")\n",
    "plt.ylabel(\"Spectral Radiance (W·sr⁻¹·m⁻²·Hz⁻¹)\")\n",
    "plt.title(\"CMB Spectrum with Fluctuation Bounds (±100 µK)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show the CMB spectrum with +100 µK fluctuations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean), label=\"T = 2.725 K\", color='blue')\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean + delta_T), '--', label=\"+100 µK\", color='green', alpha=0.8)\n",
    "plt.xlabel(\"Frequency (GHz)\")\n",
    "plt.ylabel(\"Spectral Radiance (W·sr⁻¹·m⁻²·Hz⁻¹)\")\n",
    "plt.title(\"CMB Spectrum with Fluctuation Bounds (±100 µK)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show the CMB spectrum with -100 µK fluctuations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean), label=\"T = 2.725 K\", color='blue')\n",
    "plt.plot(frequencies / 1e9, planck(frequencies, T_mean - delta_T), '--', label=\"-100 µK\", color='red', alpha=0.8)\n",
    "plt.xlabel(\"Frequency (GHz)\")\n",
    "plt.ylabel(\"Spectral Radiance (W·sr⁻¹·m⁻²·Hz⁻¹)\")\n",
    "plt.title(\"CMB Spectrum with Fluctuation Bounds (±100 µK)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "15eadc28ec4474e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cl = hp.anafast(cmb_map)\n",
    "plt.plot(cl[:200])\n",
    "plt.title(\"Low-ℓ Multipoles – Texture Signature Region\")\n",
    "plt.xlabel(\"Multipole ℓ [ℓ: inverse angular scale]\")\n",
    "plt.ylabel(\"C_ℓ [Power: variance of temperature fluctuations]\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ],
   "id": "de96fe4776a656fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# --- Compute power spectrum from CMB map ---\n",
    "cl = hp.anafast(cmb_map)         # Power spectrum\n",
    "ell = np.arange(len(cl))         # Multipole indices\n",
    "\n",
    "# --- Begin Plot ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot measured CMB power spectrum (excluding monopole)\n",
    "plt.loglog(ell[1:1500], cl[1:1500], label='CMB Power Spectrum', color='blue')\n",
    "\n",
    "# Plot theoretical scale-invariant reference curve\n",
    "ref_value = np.mean(cl[5:15])\n",
    "theory_curve = ref_value * (ell[5] * (ell[5] + 1)) / (ell[1:1500] * (ell[1:1500] + 1))\n",
    "plt.loglog(ell[1:1500], theory_curve, 'r--', label='Scale-invariant (∝ 1/ℓ(ℓ+1))')\n",
    "\n",
    "# --- Highlight Regions ---\n",
    "plt.axvspan(2, 30, color='gray', alpha=0.15, label='Sachs-Wolfe Region')\n",
    "plt.axvspan(50, 200, color='orange', alpha=0.08, label='Transition Region')\n",
    "plt.axvspan(200, 1500, color='green', alpha=0.08, label='Acoustic Peaks Region')\n",
    "\n",
    "# --- Annotations (repositioned to avoid overlap) ---\n",
    "plt.text(7, 2e-10, 'Sachs-Wolfe\\nSuper-horizon modes', fontsize=10, color='black')\n",
    "plt.text(60, 5e-20, 'Transition:\\nEarly Oscillations &\\n Projection Effects', fontsize=10, color='black')\n",
    "plt.text(300, 5e-12, 'Acoustic Peaks:\\nPhoton-Baryon Oscillations', fontsize=10, color='black')\n",
    "\n",
    "# 1st Peak marker\n",
    "plt.axvline(220, color='black', linestyle='--', alpha=0.5)\n",
    "plt.text(235, 1e-10, '1st Peak\\n(~ℓ=220)', fontsize=9, color='black')\n",
    "\n",
    "# --- Labels, Legend, Grid ---\n",
    "plt.title(\"CMB Angular Power Spectrum (Log Scale)\")\n",
    "plt.xlabel(\"Multipole ℓ [ℓ: inverse angular scale]\")\n",
    "plt.ylabel(\"C_ℓ [Power: variance of temperature fluctuations]\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.2)\n",
    "\n",
    "# --- Format axes using human-readable numbers ---\n",
    "def human_format(x, pos):\n",
    "    if x >= 1:\n",
    "        return f\"{int(x)}\"\n",
    "    else:\n",
    "        return f\"{x:.1g}\"\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(human_format))\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(human_format))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "df030401fd974066",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the power spectrum (ℓ = 0 to 199)\n",
    "ell = np.arange(len(cl))  # Define ell as the array of multipole indices\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(ell[:250], cl[:250], label='CMB Power')\n",
    "\n",
    "# Overlay topological defect regions\n",
    "plt.axvspan(2, 10, color='blue', alpha=0.3, label='Textures (ℓ ≈ 2–10)')\n",
    "plt.axvspan(2, 5, color='red', alpha=0.3, label='Domain Walls (ℓ ≈ 2–5)')\n",
    "plt.axvspan(50, 200, color='green', alpha=0.2, label='Cosmic Strings (ℓ ≈ 50–200)')\n",
    "plt.axvspan(2, 3, color='orange', alpha=0.4, label='Monopoles (ℓ ≈ 2–3)')\n",
    "\n",
    "# Labels and grid\n",
    "plt.title(\"CMB Multipole Spectrum with Topological Defect Regions\")\n",
    "plt.xlabel(\"Multipole ℓ [ℓ: inverse angular scale]\")\n",
    "plt.ylabel(\"C_ℓ [Power: variance of temperature fluctuations]\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "395f01dcb190477c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the power spectrum (ℓ = 0 to 199)\n",
    "ell = np.arange(len(cl))  # Define ell as the array of multipole indices\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(ell[:50], cl[:50], label='CMB Power')\n",
    "\n",
    "# Overlay topological defect regions\n",
    "plt.axvspan(2, 10, color='blue', alpha=0.3, label='Textures (ℓ ≈ 2–10)')\n",
    "plt.axvspan(2, 5, color='red', alpha=0.3, label='Domain Walls (ℓ ≈ 2–5)')\n",
    "plt.axvspan(2, 3, color='orange', alpha=0.4, label='Monopoles (ℓ ≈ 2–3)')\n",
    "\n",
    "# Labels and grid\n",
    "plt.title(\"CMB Multipole Spectrum with Topological Defect Regions\")\n",
    "plt.xlabel(\"Multipole ℓ [ℓ: inverse angular scale]\")\n",
    "plt.ylabel(\"C_ℓ [Power: variance of temperature fluctuations]\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ea844d697ff10b7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use same `cl` from previous block\n",
    "ell = np.arange(1, 200)  # Skip ℓ = 0 to avoid divide-by-zero\n",
    "theta_deg = 180 / ell    # Angular scale in degrees\n",
    "\n",
    "# Trim cl accordingly\n",
    "cl_trim = cl[1:200]\n",
    "\n",
    "# Plot C_ell vs angular scale θ\n",
    "plt.plot(theta_deg, cl_trim)\n",
    "plt.title(\"CMB Power Spectrum vs Angular Scale\")\n",
    "plt.xlabel(\"Angular Scale θ [degrees]\")\n",
    "plt.ylabel(\"C_ℓ [Power: variance of temperature fluctuations]\")\n",
    "plt.grid()\n",
    "plt.gca().invert_xaxis()  # Larger angular scales on the left\n",
    "plt.show()"
   ],
   "id": "7638a875a151a36f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ℓ = 1 to 199 (skip ℓ = 0 to avoid division by zero)\n",
    "theta_deg = 180 / ell\n",
    "cl_trim = cl[1:200]\n",
    "\n",
    "# Plot power vs angular scale\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(theta_deg, cl_trim, label='CMB Power')\n",
    "\n",
    "# Overlay topological defect regions in degrees\n",
    "plt.axvspan(18, 90, color='blue', alpha=0.3, label='Textures (θ ≈ 18° to 90°)')\n",
    "plt.axvspan(36, 90, color='red', alpha=0.3, label='Domain Walls (θ ≈ 36° to 90°)')\n",
    "plt.axvspan(1, 4, color='green', alpha=0.2, label='Cosmic Strings (θ ≈ 1° to 4°)')\n",
    "plt.axvspan(60, 90, color='orange', alpha=0.4, label='Monopoles (θ ≈ 60° to 90°)')\n",
    "\n",
    "# Labels and formatting\n",
    "plt.title(\"CMB Power vs Angular Scale with Topological Defect Regions\")\n",
    "plt.xlabel(\"Angular Scale θ [degrees]\")\n",
    "plt.ylabel(\"C_ℓ [Power: variance of temperature fluctuations]\")\n",
    "plt.grid()\n",
    "plt.gca().invert_xaxis()  # Large scales (low ℓ) on left\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2e2cb26eda2e7220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example of exaggerated cosmic strings",
   "id": "1f62f590ae13c173"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skimage import draw  # Changed import to use skimage.draw instead of matplotlib.pyplot.draw\n",
    "\n",
    "def simulate_cosmic_strings(map_size, num_strings):\n",
    "    map_data = np.zeros((map_size, map_size))\n",
    "    for _ in range(num_strings):\n",
    "        x = np.random.randint(0, map_size)\n",
    "        y = np.random.randint(0, map_size)\n",
    "        dx = np.random.randint(-map_size//4, map_size//4)\n",
    "        dy = np.random.randint(-map_size//4, map_size//4)\n",
    "        rr, cc = draw.line(x, y, x+dx, y+dy)  # Now using skimage.draw.line\n",
    "        map_data[rr % map_size, cc % map_size] += np.random.choice([-1, 1]) * 100e-6  # ~100 µK jump\n",
    "    return map_data\n",
    "\n",
    "# Simulate and plot\n",
    "map_size = 1000  # Reduced size for better visualization\n",
    "num_strings = 10\n",
    "cosmic_map = simulate_cosmic_strings(map_size, num_strings)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cosmic_map, cmap='RdBu_r')\n",
    "plt.colorbar(label='Temperature fluctuation (K)')\n",
    "plt.title('Simulated Cosmic Strings')\n",
    "plt.show()\n"
   ],
   "id": "127d1aff7138c278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploring the data with Machine Learning Methods\n",
    "\n",
    "In this section, we'll apply various machine learning techniques to analyze the CMB data and identify potential patterns or anomalies that might be associated with cosmic strings or other phenomena.\n"
   ],
   "id": "3918d60f92e61230"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import necessary ML libraries\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Make sure we have the CMB map loaded\n",
    "# If not already loaded, load it again\n",
    "if 'cmb_map' not in locals():\n",
    "    cmb_map = hp.read_map('data/COM_CMB_IQU-smica_2048_R3.00_full.fits', field=0)\n",
    "    nside = hp.get_nside(cmb_map)\n",
    "    npix = hp.nside2npix(nside)\n",
    "    img = hp.mollview(cmb_map, return_projected_map=True, nest=False, title='CMB Temperature Map', cmap='inferno', xsize=2000, hold=True)\n",
    "    img_cleaned = np.nan_to_num(img, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(f\"CMB map shape: {cmb_map.shape}\")\n",
    "print(f\"Projected image shape: {img_cleaned.shape}\")\n"
   ],
   "id": "94951ca05a9d602b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Feature Extraction and Dimensionality Reduction\n",
    "\n",
    "First, we'll extract features from the CMB data and reduce dimensionality to visualize patterns.\n"
   ],
   "id": "4816520929fc27d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For ML analysis, we'll work with the 2D projected map (img_cleaned)\n",
    "# Let's extract patches from the image to use as features\n",
    "\n",
    "def extract_patches(image, patch_size=16, stride=8):\n",
    "    \"\"\"Extract patches from a 2D image with a given stride.\"\"\"\n",
    "    patches = []\n",
    "    positions = []\n",
    "    h, w = image.shape\n",
    "\n",
    "    for i in range(0, h - patch_size + 1, stride):\n",
    "        for j in range(0, w - patch_size + 1, stride):\n",
    "            # Skip patches with NaN or inf values\n",
    "            patch = image[i:i+patch_size, j:j+patch_size]\n",
    "            if np.isfinite(patch).all() and not np.isnan(patch).any():\n",
    "                # Flatten the patch to a 1D array\n",
    "                patches.append(patch.flatten())\n",
    "                positions.append((i, j))\n",
    "\n",
    "    return np.array(patches), positions\n",
    "\n",
    "# Extract patches from the cleaned image\n",
    "# patch_size = 16, stride = 8\tSmall patches, overlapping\tDense coverage, good for texture analysis\n",
    "# patch_size = 32, stride = 32\tLarge, non-overlapping\tCoarse, fewer samples but high information per patch\n",
    "# patch_size = 8, stride = 4\tUltra-local\tVery sensitive to noise; good for edge detection\n",
    "# patch_size = 64, stride = 16\tLarge and overlapping\tHeavy computation; useful for large-scale pattern mining\n",
    "#\n",
    "#\n",
    "# Try three experimental combinations:\n",
    "# Test\tPatch Size\tStride\tUse Case\n",
    "# A\t    16\t        8\t    Balanced: local structure + manageable data\n",
    "# B\t    32\t        16\t    Large structures, good for global coherence\n",
    "# C\t    8\t        4\t    Detect sharp features (e.g., cosmic strings, shocks)\n",
    "patch_size = 8\n",
    "stride = 4\n",
    "patches, positions = extract_patches(img_cleaned, patch_size, stride)\n",
    "\n",
    "print(f\"Extracted {len(patches)} patches of size {patch_size}x{patch_size}\")\n",
    "\n",
    "# Standardize the patches\n",
    "scaler = StandardScaler()\n",
    "patches_scaled = scaler.fit_transform(patches)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "# PCA stands for Principal Component Analysis\n",
    "n_components = 50  # Adjust based on explained variance\n",
    "pca = PCA(n_components=n_components)\n",
    "patches_pca = pca.fit_transform(patches_scaled)\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Apply t-SNE for visualization\n",
    "# t-Distributed Stochastic Neighbor Embedding\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "patches_tsne = tsne.fit_transform(patches_pca)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(patches_tsne[:, 0], patches_tsne[:, 1], alpha=0.5, s=5)\n",
    "plt.title('t-SNE Visualization of CMB Patches')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ],
   "id": "5645af766ac7a64e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Unsupervised Learning: Clustering Analysis\n",
    "\n",
    "Now we'll apply clustering algorithms to identify groups of similar patterns in the CMB data.\n"
   ],
   "id": "732ef428e849ab2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Dynamic Optimization of Clustering Parameters\n",
    "\n",
    "To find the optimal clustering of the CMB data, we'll implement a dynamic approach that:\n",
    "\n",
    "1. Tries different numbers of clusters (from 3 to 50)\n",
    "2. For each number of clusters, runs K-means multiple times with different random initializations\n",
    "3. Calculates the silhouette score for each clustering attempt\n",
    "4. Selects the clustering with the highest silhouette score\n",
    "\n",
    "This approach helps us find the best clustering configuration automatically, rather than manually tuning parameters. The silhouette score measures how well-separated the clusters are, with higher scores indicating better-defined clusters.\n"
   ],
   "id": "8c446d0e0e97248e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Expected Silhouette Score Range for CMB Data\n",
    "\n",
    "    Good clustering:\n",
    "\n",
    "    0.5 - 1.0 → Strong evidence of cluster structure (rare for CMB unless studying clear anomalies like cold spots or non-Gaussian features).\n",
    "\n",
    "    0.3 - 0.5 → Reasonable separation (may indicate subtle non-Gaussianities or foreground contamination).\n",
    "\n",
    "    Ambiguous clustering:\n",
    "\n",
    "    0.1 - 0.3 → Weak structure (common for Gaussian CMB fluctuations; clusters may be artificial).\n",
    "\n",
    "    No meaningful clusters:\n",
    "\n",
    "    ≤ 0.1 or negative → Likely noise or overfitting (common if forcing clusters on Gaussian random fields).\n",
    "\n",
    "Key Insight:\n",
    "CMB is mostly Gaussian, so high silhouette scores are unexpected unless you're targeting specific anomalies or foregrounds. A score of 0.2-0.4 might be the realistic upper limit for most analyses.\n"
   ],
   "id": "7062a756daaf774b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to run K-means clustering multiple times and find the best silhouette score\n",
    "def find_best_kmeans(data, min_clusters=2, max_clusters=10, n_attempts=10):\n",
    "    \"\"\"\n",
    "    Run K-means clustering multiple times with different parameters to find the best silhouette score.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        The data to cluster\n",
    "    min_clusters : int\n",
    "        Minimum number of clusters to try\n",
    "    max_clusters : int\n",
    "        Maximum number of clusters to try\n",
    "    n_attempts : int\n",
    "        Number of random initializations to try for each number of clusters\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    best_kmeans : KMeans\n",
    "        The best KMeans model\n",
    "    best_labels : array\n",
    "        The cluster labels from the best model\n",
    "    best_n_clusters : int\n",
    "        The number of clusters in the best model\n",
    "    best_score : float\n",
    "        The silhouette score of the best model\n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best_kmeans = None\n",
    "    best_labels = None\n",
    "    best_n_clusters = 0\n",
    "\n",
    "    # Try different numbers of clusters\n",
    "    for n_clusters in range(min_clusters, max_clusters + 1):\n",
    "        print(f\"Trying {n_clusters} clusters...\")\n",
    "\n",
    "        # Try multiple random initializations for each number of clusters\n",
    "        for attempt in range(n_attempts):\n",
    "            # Initialize and fit KMeans\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=attempt)\n",
    "            labels = kmeans.fit_predict(data)\n",
    "\n",
    "            # Calculate silhouette score\n",
    "            score = silhouette_score(data, labels)\n",
    "            print(f\"  Attempt {attempt+1}/{n_attempts}: Silhouette Score = {score:.9f}\")\n",
    "\n",
    "            # Update best model if this one is better\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_kmeans = kmeans\n",
    "                best_labels = labels\n",
    "                best_n_clusters = n_clusters\n",
    "                print(f\"  New best score: {best_score:.9f} with {best_n_clusters} clusters\")\n",
    "\n",
    "    print(f\"\\nBest clustering: {best_n_clusters} clusters with silhouette score {best_score:.9f}\")\n",
    "    return best_kmeans, best_labels, best_n_clusters, best_score\n",
    "\n",
    "# Apply K-means clustering with multiple attempts to find the best silhouette score\n",
    "min_clusters = 3\n",
    "max_clusters = 50\n",
    "n_attempts = 100\n",
    "print(f\"Finding best K-means clustering (trying {min_clusters}-{max_clusters} clusters, {n_attempts} attempts each)...\")\n",
    "best_kmeans, cluster_labels, best_n_clusters, best_silhouette = find_best_kmeans(\n",
    "    patches_pca, min_clusters=min_clusters, max_clusters=max_clusters, n_attempts=n_attempts\n",
    ")\n",
    "\n",
    "# Visualize clusters in t-SNE space\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(patches_tsne[:, 0], patches_tsne[:, 1], c=cluster_labels, cmap='viridis', alpha=0.7, s=10)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.title(f'K-means Clustering (k={best_n_clusters}, Silhouette={best_silhouette:.3f})')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Calculate silhouette score to evaluate clustering quality\n",
    "#     Higher Silhouette Score → Better clustering quality \n",
    "#     (points are correctly assigned to tight, well-separated clusters).\n",
    "# \n",
    "#     Lower Silhouette Score → Worse clustering quality \n",
    "#     (points may be misassigned or clusters overlap).\n",
    "# 0.2-0.4 would be a good score for CMB data due to the nature of it\n",
    "print(f\"Best Silhouette Score: {best_silhouette:.3f} with {best_n_clusters} clusters\")\n",
    "\n",
    "# Visualize cluster centers in image space\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(best_n_clusters):\n",
    "    plt.subplot(1, best_n_clusters, i+1)\n",
    "    # Get the center of the cluster in original space\n",
    "    center = pca.inverse_transform(best_kmeans.cluster_centers_[i])\n",
    "    center = scaler.inverse_transform([center])[0]\n",
    "    # Reshape to patch size\n",
    "    center = center.reshape(patch_size, patch_size)\n",
    "    plt.imshow(center, cmap='inferno')\n",
    "    plt.title(f'Cluster {i}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Map clusters back to the original image\n",
    "cluster_map = np.zeros(img_cleaned.shape)\n",
    "cluster_count = np.zeros(img_cleaned.shape)\n",
    "\n",
    "for (i, j), label in zip(positions, cluster_labels):\n",
    "    cluster_map[i:i+patch_size, j:j+patch_size] += label\n",
    "    cluster_count[i:i+patch_size, j:j+patch_size] += 1\n",
    "\n",
    "# Average the cluster labels where patches overlap\n",
    "mask = cluster_count > 0\n",
    "cluster_map[mask] /= cluster_count[mask]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(cluster_map, cmap='viridis')\n",
    "plt.title(f'Cluster Map of CMB Data (k={best_n_clusters}, Silhouette={best_silhouette:.3f})')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ],
   "id": "c32d1c7c10cce2cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check variance retention\n",
    "# Aim for ≥95% for CMB (unlike images, where 80-90% may suffice).\n",
    "print(f\"Variance retained: {np.sum(pca.explained_variance_ratio_):.2%}\")"
   ],
   "id": "f40a1aa650fb1318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare to UMAP (often more stable)\n",
    "from umap import UMAP\n",
    "umap_emb = UMAP(n_components=2).fit_transform(patches_pca)"
   ],
   "id": "dbd8e2f7382c527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Overlay clusters on a CMB map\n",
    "plt.imshow(cluster_map, cmap='viridis', alpha=0.5)\n",
    "plt.imshow(cmb_map, cmap='inferno', alpha=0.5)"
   ],
   "id": "99144d40a0595806",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "labels = clusterer.fit_predict(patches_pca)"
   ],
   "id": "f22305733ef60d95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inertias = []\n",
    "for k in range(min_clusters, max_clusters+1):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(patches_pca)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(min_clusters, max_clusters+1), inertias, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ],
   "id": "f0b2e6f2a8bcbe41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check cluster sizes\n",
    "unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "# Visualize problematic clusters\n",
    "problem_cluster = 0  # Example\n",
    "problem_indices = np.where(cluster_labels == problem_cluster)[0]\n",
    "plt.scatter(patches_tsne[problem_indices, 0],\n",
    "           patches_tsne[problem_indices, 1])\n",
    "plt.title(f'Problematic Cluster {problem_cluster}')\n",
    "plt.show()"
   ],
   "id": "c413db825255872a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Anomaly Detection\n",
    "\n",
    "Let's use Isolation Forest to detect anomalies in the CMB data that might correspond to cosmic strings or other interesting features.\n"
   ],
   "id": "5b4933f658f780f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply Isolation Forest for anomaly detection\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "anomaly_scores = iso_forest.fit_predict(patches_pca)\n",
    "\n",
    "# Convert to anomaly score (higher = more anomalous)\n",
    "anomaly_scores = -1 * anomaly_scores  # -1 becomes +1 (anomaly), 1 becomes -1 (normal)\n",
    "print(f\"Anomaly Score Range: {anomaly_scores.min()} to {anomaly_scores.max()}\")\n",
    "\n",
    "# Visualize anomalies in t-SNE space\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(patches_tsne[:, 0], patches_tsne[:, 1], c=anomaly_scores, cmap='coolwarm', alpha=0.7, s=10)\n",
    "plt.colorbar(scatter, label='Anomaly Score')\n",
    "plt.title('Anomaly Detection in CMB Patches')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Map anomaly scores back to the original image\n",
    "anomaly_map = np.zeros(img_cleaned.shape)\n",
    "anomaly_count = np.zeros(img_cleaned.shape)\n",
    "\n",
    "for (i, j), score in zip(positions, anomaly_scores):\n",
    "    anomaly_map[i:i+patch_size, j:j+patch_size] += score\n",
    "    anomaly_count[i:i+patch_size, j:j+patch_size] += 1\n",
    "\n",
    "# Average the anomaly scores where patches overlap\n",
    "mask = anomaly_count > 0\n",
    "anomaly_map[mask] /= anomaly_count[mask]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(anomaly_map, cmap='coolwarm')\n",
    "plt.title('Anomaly Map of CMB Data (Potential Cosmic String Candidates)')\n",
    "plt.colorbar(label='Anomaly Score')\n",
    "plt.show()\n"
   ],
   "id": "6cb05b2ec54aa324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features (principal components) are most important for distinguishing clusters and anomalies.\n"
   ],
   "id": "697df93ca9035124"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze the most important principal components\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(n_components), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Importance of Principal Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Analyze the first few principal components\n",
    "n_display = min(5, n_components)\n",
    "plt.figure(figsize=(15, 3*n_display))\n",
    "for i in range(n_display):\n",
    "    plt.subplot(n_display, 1, i+1)\n",
    "    component = pca.components_[i].reshape(1, -1)\n",
    "    component_image = scaler.inverse_transform(component)[0].reshape(patch_size, patch_size)\n",
    "    plt.imshow(component_image, cmap='coolwarm')\n",
    "    plt.title(f'Principal Component {i+1}')\n",
    "    plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "80b1b9345b2ea876",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Correlation with Edge Detection\n",
    "\n",
    "Let's compare our ML-based anomaly detection with the edge detection performed earlier to see if they identify similar features.\n"
   ],
   "id": "fb828f9cb59926f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure we have the edge detection results\n",
    "if 'edges' not in locals():\n",
    "    edges = ndimage.sobel(img_cleaned)\n",
    "\n",
    "# Normalize both maps for comparison\n",
    "edges_norm = (edges - np.min(edges)) / (np.max(edges) - np.min(edges))\n",
    "anomaly_norm = (anomaly_map - np.min(anomaly_map)) / (np.max(anomaly_map) - np.min(anomaly_map))\n",
    "\n",
    "# Calculate correlation between edge detection and anomaly detection\n",
    "valid_mask = ~np.isnan(edges_norm) & ~np.isnan(anomaly_norm)\n",
    "correlation = np.corrcoef(edges_norm[valid_mask].flatten(), anomaly_norm[valid_mask].flatten())[0, 1]\n",
    "print(f\"Correlation between edge detection and anomaly detection: {correlation:.3f}\")\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(edges_norm, cmap='inferno')\n",
    "plt.title('Edge Detection')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(anomaly_norm, cmap='coolwarm')\n",
    "plt.title('Anomaly Detection')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(edges_norm, cmap='inferno', alpha=0.7)\n",
    "plt.imshow(anomaly_norm, cmap='coolwarm', alpha=0.3)\n",
    "plt.title('Edge + Anomaly Overlay')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "d7c18ae0c8994923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "We've applied several machine learning techniques to analyze the CMB data:\n",
    "\n",
    "1. **Feature Extraction**: Extracted patches from the CMB map and reduced dimensionality with PCA\n",
    "2. **Clustering**: Identified distinct patterns in the CMB data using K-means\n",
    "3. **Anomaly Detection**: Used Isolation Forest to find unusual patterns that might correspond to cosmic strings\n",
    "4. **Feature Importance**: Analyzed which principal components are most significant\n",
    "5. **Correlation Analysis**: Compared ML-based anomaly detection with traditional edge detection\n",
    "\n",
    "These techniques provide complementary views of the CMB data and can help identify potential cosmic string candidates or other interesting features that might not be apparent through traditional analysis methods.\n",
    "\n",
    "The correlation between edge detection and anomaly detection suggests that ML methods can identify similar structures to traditional methods, but may also reveal additional patterns not captured by edge detection alone.\n"
   ],
   "id": "9c8752af6db19eb8"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
